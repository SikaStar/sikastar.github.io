<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yongxing Dai</title>
  
  <meta name="author" content="Yongxing Dai">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/pku_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yongxing Dai</name>
              </p>
              <p> I am a fourth year Ph.D student at the 
                <a href="http://idm.pku.edu.cn/en/">National Engineering Research Center of Visual Technology (NELVT)</a>,
                <a href="https://cs.pku.edu.cn/English/Home.htm">School of Computer Science</a>,
                <a href="https://english.pku.edu.cn/">Peking University</a>, supervised by Prof. <a href="https://scholar.google.com/citations?user=hsXZOgIAAAAJ&hl=zh-CN">Ling-Yu Duan</a>. 
                In 2018, I obtained my B.Eng. degree in computer 
                science and technology from <a href="https://en.xidian.edu.cn/">Xidian University</a>, Xi’an, China.
              </p>
              <p> My current research focuses on computer vision and trasnfer learning, especially person re-identification, domain adaptation, and domain generalization.
              </p>
              <p style="text-align:center">
                <a href="mailto:yongxingdai@pku.edu.cn">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=j8slWLIAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/SikaStar">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/daiyongxing.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/daiyongxing.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
	    <p>
              <strong>2022-03:</strong> Invitated as a reviewer for NeurIPS 2022.
            </p>
            <p>
              <strong>2022-01:</strong> One paper is accepted by ICLR 2022.
            </p>
	    <p>
              <strong>2021-09:</strong> One paper is accepted by NeurIPS 2021.
            </p>
            <p>
              <strong>2021-07:</strong> One paper is accepted by ICCV 2021 and one paper is accepted by TIP.
            </p>
          </td>
        </tr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications & Preprints</heading>
              <p>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="idm_plus_plus_stop()" onmouseover="idm_plus_plus_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/IDM++.png' width="160">
              </div>
              <script type="text/javascript">
                function idm_plus_plus_start() {
                  document.getElementById('idm_image').style.opacity = "1";
                }

                function idm_stop() {
                  document.getElementById('idm_image').style.opacity = "0";
                }
                idm_plus_plus_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://arxiv.org/abs/2108.02413">
                <papertitle>Bridging the Source-to-target Gap for Cross-domain Person Re-Identification with Intermediate Domains</papertitle>
              </a>
              <br>
              <strong>Yongxing Dai</strong>,
              <a href="https://yifansun-reid.github.io/">Yifan Sun</a>,
              <a href="https://ljchangyu.wixsite.com/liujun021">Jun Liu</a>,
              <a href="https://scholar.google.com/citations?user=odJ3HhEAAAAJ&hl=en">Zekun Tong</a>,
              <a href="https://scholar.google.com/citations?user=RMSuNFwAAAAJ&hl=zh-CN">Yi Yang</a>,
              <a href="https://scholar.google.com/citations?user=hsXZOgIAAAAJ&hl=zh-CN">Ling-Yu Duan</a>
              <br>
              <em>Arxiv preprint</em>, 2022
              <br>
              <a href="https://arxiv.org/abs/2203.01682">paper</a>
              /
              <a href="https://github.com/SikaStar/IDM">code</a>
              /
              <a href="data/dai2022bridging.bib">bibtex</a>
              <p></p>
              <p>IDM++ is a journal extension of IDM (ICCV 2021 Oral). We further propose a Mirrors Generation Module (MGM) to reinforce IDM into IDM++. IDM++ provides a unified framework 
                 for two popular cross-domain re-ID scenarios (i.e., UDA and DG). Twelve UDA re-ID benchmarks and two DG re-ID protocols validate that IDM++ brings general improvement and 
                 sets new state of the art for both scenarios.
              </p>
            </td>
          </tr> 

          <tr onmouseout="dsu_stop()" onmouseover="dsu_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ICLR_DSU.png' width="160">
              </div>
              <script type="text/javascript">
                function dsu_start() {
                  document.getElementById('dsu_image').style.opacity = "1";
                }

                function dsu_stop() {
                  document.getElementById('dsu_image').style.opacity = "0";
                }
                idm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=6HN7LHyzGgC">
                <papertitle>Uncertainty Modeling for Out-of-Distribution Generalization</papertitle>
              </a>
              <br>
              Xiaotong Li,
              <strong>Yongxing Dai</strong>,
              <a href="https://geyixiao.com">Yixiao Ge</a>,
              <a href="https://ljchangyu.wixsite.com/liujun021">Jun Liu</a>,
              <a href="https://scholar.google.com/citations?user=4oXBp9UAAAAJ&hl=zh-CN">Ying Shan</a>,
              <a href="https://scholar.google.com/citations?user=hsXZOgIAAAAJ&hl=zh-CN">Ling-Yu Duan</a>
              <br>
              <em>ICLR</em>, 2022
              <br>
              <a href="https://openreview.net/forum?id=6HN7LHyzGgC">paper</a>
              /
              <a href="https://github.com/lixiaotong97/DSU">code</a>
              /
              <a href="data/iclr2022dsu.bib">bibtex</a>
              <p></p>
              <p>We improve the network generalization ability by modeling the uncertainty 
                 of domain shifts with synthesized feature statistics during training. Our method shows its superiority on a wide range of out-of-distribution (OOD) vision tasks including image classification, semantic segmentation, and instance retrieval.</p>
            </td>
          </tr> 
          
          <tr onmouseout="digcl_stop()" onmouseover="digcl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/neurips_digcl.png' width="160">
              </div>
              <script type="text/javascript">
                function idm_start() {
                  document.getElementById('digcl_image').style.opacity = "1";
                }

                function idm_stop() {
                  document.getElementById('digcl_image').style.opacity = "0";
                }
                idm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=yLEcG62ANX">
                <papertitle>Digraph Contrastive Learning</papertitle>
              </a>
              <br>
              <a href="https://zekuntong.com/">Zekun Tong</a>,
              <a href="https://yuxuanliang.com/">Yuxuan Liang</a>,
              <a href="https://henghuiding.github.io/">Henghui Ding</a>,
              <strong>Yongxing Dai</strong>,
              <a href="https://scholar.google.com/citations?user=l4LPBs0AAAAJ&hl=en">Xinke Li</a>,
              <a href="https://changhu.wang/">Changhu Wang</a>,
              
              <br>
							<em>NeurIPS</em>, 2021
              <br>
              <a href="https://openreview.net/forum?id=yLEcG62ANX">paper</a>
							/
              <a href="https://github.com/flyingtango/DiGCL">code</a>
              /
              <a href="data/tong2021directed.bib">bibtex</a>
              <p></p>
              <p>We design a digraph data augmentation method called Laplacian perturbation and theoretically 
                analyze how it provides contrastive information without changing the digraph structure. 
              </p>
            </td>
          </tr> 

          <tr onmouseout="idm_stop()" onmouseover="idm_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ICCV_IDM.PNG' width="160">
              </div>
              <script type="text/javascript">
                function idm_start() {
                  document.getElementById('idm_image').style.opacity = "1";
                }

                function idm_stop() {
                  document.getElementById('idm_image').style.opacity = "0";
                }
                idm_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://arxiv.org/abs/2108.02413">
                <papertitle>IDM: An Intermediate Domain Module for Domain Adaptive Person Re-ID</papertitle>
              </a>
              <br>
              <strong>Yongxing Dai</strong>,
              <a href="https://ljchangyu.wixsite.com/liujun021">Jun Liu</a>,
              <a href="https://yifansun-reid.github.io/">Yifan Sun</a>,
              <a href="https://scholar.google.com/citations?user=odJ3HhEAAAAJ&hl=en">Zekun Tong</a>,
              Chi Zhang</a>,
              <a href="https://scholar.google.com/citations?user=hsXZOgIAAAAJ&hl=zh-CN">Ling-Yu Duan</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Dai_IDM_An_Intermediate_Domain_Module_for_Domain_Adaptive_Person_Re-ID_ICCV_2021_paper.html">paper</a>
              /
              <a href="http://arxiv.org/abs/2108.02413">arXiv</a>
							/
              <a href="https://github.com/SikaStar/IDM">code</a>
              /
              <a href="data/dai2021idm.bib">bibtex</a>
              <p></p>
              <p>IDM is a plug-and-play module to generate intermediate domains' representations, 
                which can bridge source and target domains in unsupervised domain adaptive person re-ID.</p>
            </td>
          </tr> 

          <tr onmouseout="dualrefinement_stop()" onmouseover="dualrefinement_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/TIP_dual.PNG' width="160">
              </div>
              <script type="text/javascript">
                function dualrefinement_start() {
                  document.getElementById('dualrefinement_image').style.opacity = "1";
                }

                function dualrefinement_stop() {
                  document.getElementById('dualrefinement_image').style.opacity = "0";
                }
                dualrefinement_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://github.com/SikaStar/Dual-Refinement">
                <papertitle>Dual-Refinement: Joint Label and Feature Refinement for Unsupervised Domain Adaptive Person Re-Identification</papertitle>
              </a>
              <br>
              <strong>Yongxing Dai</strong>,
              <a href="https://ljchangyu.wixsite.com/liujun021">Jun Liu</a>,
              <a href="https://scholar.google.com/citations?user=hR0hxdgAAAAJ&hl=zh-CN">Yan Bai</a>,
              <a href="https://scholar.google.com/citations?user=odJ3HhEAAAAJ&hl=en">Zekun Tong</a>,
              <a href="https://scholar.google.com/citations?user=hsXZOgIAAAAJ&hl=zh-CN">Ling-Yu Duan</a>
              <br>
							<em>IEEE Transactions on Image Processing (TIP)</em>, 2021 &nbsp
              <br>
              <a href="https://ieeexplore.ieee.org/document/9513260">paper</a>
							/
              <a href="https://arxiv.org/abs/2012.13689">arXiv</a>
							/
              <a href="https://github.com/SikaStar/Dual-Refinement">code</a>
              /
              <a href="data/dai2021dual.bib">bibtex</a>
              <p></p>
              <p>Dual-Refinement can jointly refine pseudo labels at the off-line clustering phase and features at the on-line training phase, to alternatively boost the label purity and feature discriminability in the target domain for
                more reliable re-ID.</p>
            </td>
          </tr> 

          <tr onmouseout="ramoe_stop()" onmouseover="ramoe_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/cvpr_ramoe.PNG' width="160">
              </div>
              <script type="text/javascript">
                function ramoe_start() {
                  document.getElementById('ramoe_image').style.opacity = "1";
                }

                function ramoe_stop() {
                  document.getElementById('ramoe_image').style.opacity = "0";
                }
                ramoe_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Generalizable_Person_Re-Identification_With_Relevance-Aware_Mixture_of_Experts_CVPR_2021_paper.pdf">
                <papertitle>Generalizable Person Re-identification with Relevance-aware Mixture of Experts</papertitle>
              </a>
              <br>
              <strong>Yongxing Dai</strong>,
              Xiaotong Li</a>,
              <a href="https://ljchangyu.wixsite.com/liujun021">Jun Liu</a>,
              <a href="https://scholar.google.com/citations?user=odJ3HhEAAAAJ&hl=en">Zekun Tong</a>,
              <a href="https://scholar.google.com/citations?user=hsXZOgIAAAAJ&hl=zh-CN">Ling-Yu Duan</a>
              <br>
							<em>CVPR</em>, 2021 &nbsp
              <br>
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Generalizable_Person_Re-Identification_With_Relevance-Aware_Mixture_of_Experts_CVPR_2021_paper.pdf">paper</a>
              /
              <a href="https://arxiv.org/abs/2012.13689">arXiv</a>
              /
              <a href="data/dai2021ramoe.bib">bibtex</a>
              <p></p>
              <p>We propose a novel method called the relevance-aware mixture of experts (RaMoE), 
                using an effective voting-based mixture mechanism to dynamically leverage source domains’
                diverse characteristics to improve the model’s generalization</p>
            </td>
          </tr> 


          <tr onmouseout="ijcai_stop()" onmouseover="ijcai_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/ijcai.PNG' width="160">
              </div>
              <script type="text/javascript">
                function ijcai_start() {
                  document.getElementById('ijcai_image').style.opacity = "1";
                }

                function ijcai_stop() {
                  document.getElementById('ijcai_image').style.opacity = "0";
                }
                ijcai_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ijcai.org/proceedings/2020/0066.pdf">
                <papertitle>Disentangled Feature Learning Network for Vehicle Re-Identification</papertitle>
              </a>
              <br>
              <a href="https://scholar.google.com/citations?user=hR0hxdgAAAAJ&hl=zh-CN">Yan Bai</a>,
              <a href="https://scholar.google.com/citations?user=xDTcPZIAAAAJ&hl=zh-CN">Yihang Lou</a>,
              <strong>Yongxing Dai</strong>,
              <a href="https://ljchangyu.wixsite.com/liujun021">Jun Liu</a>,
              Ziqian Chen,
              <a href="https://scholar.google.com/citations?user=hsXZOgIAAAAJ&hl=zh-CN">Ling-Yu Duan</a>
              <br>
							<em>IJCAI</em>, 2020 &nbsp
              <br>
              <a href="https://www.ijcai.org/proceedings/2020/0066.pdf">paper</a>
              /
              <a href="data/ijcai2020.bib">bibtex</a>
              <p></p>
              <p>We propose a Disentangled Feature Learning Network (DFLNet) to learn orientation specific and common features 
                concurrently. Moreover, to effectively use these two types of features for ReID, we further design a feature metric 
                alignment scheme to ensure the consistency of the metric scales.</p>
            </td>
          </tr> 


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors</heading>
              <p>
                <a href="https://idm.pku.edu.cn/info/1012/1449.htm">NELVT Outstanding Student &nbsp &nbsp 2021</a>
              </p>
              <p>
                <a href="https://grs.pku.edu.cn/jzgz/dtxx1/tzgg1/356246.htm">Peking University President Scholarship &nbsp &nbsp 2021-2022</a>
              </p>
              <p>
                Lee Wai Wing Scholarship &nbsp &nbsp 2020-2021</a>
              </p>
              <p>
                Merit Student of Peking University &nbsp &nbsp 2021</a>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic Services</heading>
              <p>
                <strong>Journal Reviewer:</strong>TIP, TMM, Neurocomputing</a>
              </p>
              <p>
                <strong>Conference Reviewer:</strong>NeurIPS 2022, ICLR 2022</a>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
